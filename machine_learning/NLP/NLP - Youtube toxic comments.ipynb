{"cells":[{"cell_type":"code","execution_count":1,"id":"e4fe0771","metadata":{"id":"e4fe0771","executionInfo":{"status":"ok","timestamp":1662569575211,"user_tz":-120,"elapsed":758,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","id":"dc8d3205","metadata":{"id":"dc8d3205"},"source":["# Youtube toxic comments"]},{"cell_type":"markdown","id":"66c086cd","metadata":{"id":"66c086cd"},"source":["About Dataset\n","This is a hand-labelled toxicity data set containing 1000 comments crawled from YouTube videos about the Ferguson unrest in 2014. In addition to toxicity, this data set contains labels for multiple subclassifications of toxicity which form a hierarchical structure. Each comment can have multiple of these labels assigned. The structure can be seen in the following enumeration:\n","\n","__IsToxic__\n","\n","_and sub-categories :_\n","- IsAbusive\n","- IsThreat\n","- IsProvocative\n","- IsObscene\n","- IsHatespeech\n","- IsRacist\n","- IsNationalist\n","- IsSexist\n","- IsHomophobic\n","- IsReligiousHate\n","- IsRadicalism"]},{"cell_type":"markdown","id":"ba2e3fa1","metadata":{"id":"ba2e3fa1"},"source":["### loading and visualizing data:"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"366qgSbpzjkq","executionInfo":{"status":"ok","timestamp":1662569606089,"user_tz":-120,"elapsed":26703,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}},"outputId":"a8fee35c-5050-4f90-b3f4-4ce533993987"},"id":"366qgSbpzjkq","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"id":"a1a4d95b","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"a1a4d95b","executionInfo":{"status":"ok","timestamp":1662569607266,"user_tz":-120,"elapsed":1182,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}},"outputId":"5a1208b9-fc32-4e0f-87c7-89d8e48b7ec7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Text  IsToxic  IsAbusive  \\\n","0  If only people would just take a step back and...    False      False   \n","1  Law enforcement is not trained to shoot to app...     True       True   \n","2  \\nDont you reckon them 'black lives matter' ba...     True       True   \n","\n","   IsThreat  IsProvocative  IsObscene  IsHatespeech  IsRacist  IsNationalist  \\\n","0     False          False      False         False     False          False   \n","1     False          False      False         False     False          False   \n","2     False          False       True         False     False          False   \n","\n","   IsSexist  IsHomophobic  IsReligiousHate  IsRadicalism  \n","0     False         False            False         False  \n","1     False         False            False         False  \n","2     False         False            False         False  "],"text/html":["\n","  <div id=\"df-5efe71f5-fb0c-4a39-872e-9f775f1621a0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>IsToxic</th>\n","      <th>IsAbusive</th>\n","      <th>IsThreat</th>\n","      <th>IsProvocative</th>\n","      <th>IsObscene</th>\n","      <th>IsHatespeech</th>\n","      <th>IsRacist</th>\n","      <th>IsNationalist</th>\n","      <th>IsSexist</th>\n","      <th>IsHomophobic</th>\n","      <th>IsReligiousHate</th>\n","      <th>IsRadicalism</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>If only people would just take a step back and...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Law enforcement is not trained to shoot to app...</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\\nDont you reckon them 'black lives matter' ba...</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5efe71f5-fb0c-4a39-872e-9f775f1621a0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5efe71f5-fb0c-4a39-872e-9f775f1621a0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5efe71f5-fb0c-4a39-872e-9f775f1621a0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["data = pd.read_csv('drive/MyDrive/Colab notebooks/archive/youtoxic_english_1000.csv')\n","data = data.drop(['CommentId','VideoId'],axis=1)\n","data.head(3)"]},{"cell_type":"markdown","id":"c73e2c15","metadata":{"id":"c73e2c15"},"source":["# 1. Binary Classification : Toxic comment or not ?\n","\n","## 1.1 TFIDF + Classifier"]},{"cell_type":"code","execution_count":4,"id":"02cd5714","metadata":{"id":"02cd5714","executionInfo":{"status":"ok","timestamp":1662569614205,"user_tz":-120,"elapsed":1979,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":5,"id":"58ed13c7","metadata":{"id":"58ed13c7","executionInfo":{"status":"ok","timestamp":1662569614207,"user_tz":-120,"elapsed":9,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}}},"outputs":[],"source":["train, test = train_test_split(data, test_size=0.2)\n","x_train = train['Text'].values; y_train = train['IsToxic'].values;\n","x_test = test['Text'].values; y_test = test['IsToxic'].values;"]},{"cell_type":"markdown","id":"a0585dc8","metadata":{"id":"a0585dc8"},"source":["### creating my sklearn Transformer "]},{"cell_type":"code","execution_count":6,"id":"ec3c4490","metadata":{"id":"ec3c4490","executionInfo":{"status":"ok","timestamp":1662569617530,"user_tz":-120,"elapsed":433,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}}},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.base import TransformerMixin\n","\n","class MyTransformer(TransformerMixin):\n","    def __init__(self, ):\n","        self.tfidf_vectorizer = TfidfVectorizer()\n","    \n","    def fit(self, X, y):\n","        self.tfidf_vectorizer.fit(X)\n","        return self\n","\n","    def transform(self, X):\n","        return self.tfidf_vectorizer.transform(X)\n","        "]},{"cell_type":"markdown","id":"a737df8b","metadata":{"id":"a737df8b"},"source":["## testing accuracy of different types of classifier :"]},{"cell_type":"code","execution_count":7,"id":"b22e25c5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b22e25c5","executionInfo":{"status":"ok","timestamp":1662569620863,"user_tz":-120,"elapsed":436,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}},"outputId":"2f7578ed-8e51-4ed4-cda3-112c8627ffdf"},"outputs":[{"output_type":"stream","name":"stdout","text":["LogisticRegression accuracy: 70.5%\n","SVC accuracy: 71.5%\n","LinearSVC accuracy: 73.5%\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC, LinearSVC, LinearSVR\n","from sklearn.pipeline import Pipeline\n","\n","models = [Pipeline([('vectorizer',MyTransformer()),\n","                 (\"classifier\",clf())]) for clf in [LogisticRegression, SVC, LinearSVC ]]\n","\n","for model in models :    \n","    model.fit(x_train, y_train);\n","    print(str(model['classifier'])[:-2], 'accuracy:', f'{100*model.score(x_test,y_test)}%')"]},{"cell_type":"markdown","source":["## 1.2 Using NLP pretrained model BERT + keras NN"],"metadata":{"id":"m98Z27xk0QfY"},"id":"m98Z27xk0QfY"},{"cell_type":"code","source":["! pip install transformers\n","! pip install tokenization\n","! pip install bert-tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UbPS8RD30d84","executionInfo":{"status":"ok","timestamp":1662569641721,"user_tz":-120,"elapsed":17964,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}},"outputId":"d2c3fcda-2013-4c05-a48e-26122e164e6f"},"id":"UbPS8RD30d84","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 32.8 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 57.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 76.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tokenization\n","  Downloading tokenization-1.0.7-py3-none-any.whl (10 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from tokenization) (2022.6.2)\n","Installing collected packages: tokenization\n","Successfully installed tokenization-1.0.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bert-tensorflow\n","  Downloading bert_tensorflow-1.0.4-py2.py3-none-any.whl (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 3.0 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bert-tensorflow) (1.15.0)\n","Installing collected packages: bert-tensorflow\n","Successfully installed bert-tensorflow-1.0.4\n"]}]},{"cell_type":"code","source":["from transformers import BertTokenizer, TFBertModel, BertConfig\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","m_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n","bert_layer = hub.KerasLayer(m_url, trainable=False)"],"metadata":{"id":"a2duxtzB0WPH","executionInfo":{"status":"ok","timestamp":1662570525114,"user_tz":-120,"elapsed":6394,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}}},"id":"a2duxtzB0WPH","execution_count":36,"outputs":[]},{"cell_type":"code","source":["from bert import tokenization\n","vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n","do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n","tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n","\n","def bert_encode(texts, tokenizer, max_len=512):\n","    all_tokens = []\n","    all_masks = []\n","    all_segments = []\n","    \n","    for text in texts:\n","        text = tokenizer.tokenize(text)\n","        \n","        text = text[:max_len-2]\n","        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n","        pad_len = max_len-len(input_sequence)\n","        \n","        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n","        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n","        segment_ids = [0] * max_len\n","        \n","        all_tokens.append(tokens)\n","        all_masks.append(pad_masks)\n","        all_segments.append(segment_ids)\n","        \n","    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"],"metadata":{"id":"Io2ceVcU1g3R","executionInfo":{"status":"ok","timestamp":1662571008200,"user_tz":-120,"elapsed":500,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}}},"id":"Io2ceVcU1g3R","execution_count":64,"outputs":[]},{"cell_type":"code","source":["def build_model(bert_layer, max_len=512):\n","    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n","    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n","    \n","    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n","    \n","    clf_output = sequence_output[:, 0, :]\n","    \n","    lay = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n","    # lay = tf.keras.layers.Dropout(0.2)(lay)\n","    # lay = tf.keras.layers.Dense(32, activation='relu')(lay)\n","    # lay = tf.keras.layers.Dropout(0.2)(lay)\n","    out = tf.keras.layers.Dense(1, activation='sigmoid')(lay)\n","    \n","    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n","    model.compile(tf.keras.optimizers.Adam(lr=2e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","    \n","    return model"],"metadata":{"id":"cvnoqDXn2BeS","executionInfo":{"status":"ok","timestamp":1662571008599,"user_tz":-120,"elapsed":2,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}}},"id":"cvnoqDXn2BeS","execution_count":65,"outputs":[]},{"cell_type":"code","source":["import sys\n","from absl import flags\n","sys.argv=['preserve_unused_tokens=False']\n","flags.FLAGS(sys.argv)\n","\n","max_len = 150\n","train_input = bert_encode(train['Text'].values, tokenizer, max_len=max_len)\n","test_input = bert_encode(test[\"Text\"].values, tokenizer, max_len=max_len)"],"metadata":{"id":"ZI1bbiqs2dmI","executionInfo":{"status":"ok","timestamp":1662571009702,"user_tz":-120,"elapsed":698,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}}},"id":"ZI1bbiqs2dmI","execution_count":66,"outputs":[]},{"cell_type":"code","source":["train_labels = train['IsToxic']\n","test_labels = test['IsToxic']"],"metadata":{"id":"Sdrz8sH83Gt_","executionInfo":{"status":"ok","timestamp":1662571010210,"user_tz":-120,"elapsed":510,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}}},"id":"Sdrz8sH83Gt_","execution_count":67,"outputs":[]},{"cell_type":"code","source":["model = build_model(bert_layer, max_len=max_len)\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RA8vSpEB3QyT","executionInfo":{"status":"ok","timestamp":1662571010628,"user_tz":-120,"elapsed":420,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}},"outputId":"0b9b6d48-d29f-47a0-b7e7-775f92256caa"},"id":"RA8vSpEB3QyT","execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_9\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_word_ids (InputLayer)    [(None, 150)]        0           []                               \n","                                                                                                  \n"," input_mask (InputLayer)        [(None, 150)]        0           []                               \n","                                                                                                  \n"," segment_ids (InputLayer)       [(None, 150)]        0           []                               \n","                                                                                                  \n"," keras_layer_1 (KerasLayer)     multiple             109482241   ['input_word_ids[0][0]',         \n","                                                                  'input_mask[0][0]',             \n","                                                                  'segment_ids[0][0]']            \n","                                                                                                  \n"," tf.__operators__.getitem_9 (Sl  (None, 768)         0           ['keras_layer_1[6][1]']          \n"," icingOpLambda)                                                                                   \n","                                                                                                  \n"," dense_26 (Dense)               (None, 64)           49216       ['tf.__operators__.getitem_9[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dense_27 (Dense)               (None, 1)            65          ['dense_26[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,531,522\n","Trainable params: 49,281\n","Non-trainable params: 109,482,241\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.fit(\n","    train_input, train_labels,\n","    epochs=10,\n","    validation_data=(test_input,test_labels),\n","    batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1PfVvRdI3XuI","executionInfo":{"status":"ok","timestamp":1662571155826,"user_tz":-120,"elapsed":144113,"user":{"displayName":"Antoine Perrot","userId":"14214104379254519149"}},"outputId":"5f8cf97a-d7c6-44f5-fb90-352378f44aee"},"id":"1PfVvRdI3XuI","execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","25/25 [==============================] - 14s 474ms/step - loss: 0.6803 - accuracy: 0.5738 - val_loss: 0.6630 - val_accuracy: 0.6150\n","Epoch 2/10\n","25/25 [==============================] - 11s 463ms/step - loss: 0.6123 - accuracy: 0.6938 - val_loss: 0.6226 - val_accuracy: 0.6700\n","Epoch 3/10\n","25/25 [==============================] - 12s 475ms/step - loss: 0.5728 - accuracy: 0.7325 - val_loss: 0.6043 - val_accuracy: 0.6900\n","Epoch 4/10\n","25/25 [==============================] - 12s 465ms/step - loss: 0.5437 - accuracy: 0.7462 - val_loss: 0.5914 - val_accuracy: 0.6950\n","Epoch 5/10\n","25/25 [==============================] - 11s 459ms/step - loss: 0.5205 - accuracy: 0.7575 - val_loss: 0.5812 - val_accuracy: 0.7150\n","Epoch 6/10\n","25/25 [==============================] - 11s 452ms/step - loss: 0.5005 - accuracy: 0.7738 - val_loss: 0.5741 - val_accuracy: 0.7300\n","Epoch 7/10\n","25/25 [==============================] - 11s 450ms/step - loss: 0.4856 - accuracy: 0.7800 - val_loss: 0.5765 - val_accuracy: 0.7200\n","Epoch 8/10\n","25/25 [==============================] - 11s 453ms/step - loss: 0.4712 - accuracy: 0.7788 - val_loss: 0.5745 - val_accuracy: 0.7150\n","Epoch 9/10\n","25/25 [==============================] - 11s 459ms/step - loss: 0.4592 - accuracy: 0.8012 - val_loss: 0.5705 - val_accuracy: 0.7200\n","Epoch 10/10\n","25/25 [==============================] - 11s 461ms/step - loss: 0.4486 - accuracy: 0.7937 - val_loss: 0.5729 - val_accuracy: 0.7200\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7efa4d50a810>"]},"metadata":{},"execution_count":69}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}